from flask import Flask, render_template, request, jsonify, Response
import requests
import time
import socket
import ssl
import subprocess
import re
import sqlite3
from urllib.parse import urlparse

app = Flask(__name__)

# Database setup
def init_db():
    conn = sqlite3.connect('sonic_boom.db')
    cursor = conn.cursor()
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é —Ç–∞–±–ª–∏—Ü—É –∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å –ø–æ–ª–Ω–æ–π —Å—Ö–µ–º–æ–π
    cursor.execute('DROP TABLE IF EXISTS analysis_history')
    
    # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∞–Ω–∞–ª–∏–∑–æ–≤ —Å –ø–æ–ª–Ω–æ–π —Å—Ö–µ–º–æ–π
    cursor.execute('''
        CREATE TABLE analysis_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            url TEXT NOT NULL,
            load_time REAL,
            dns_info TEXT,
            ssl_info TEXT,
            avg_ping TEXT,
            ping_result TEXT,
            page_size INTEGER,
            seo_score TEXT,
            seo_score_numeric INTEGER,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            is_favorite BOOLEAN DEFAULT 0,
            tags TEXT,
            notes TEXT,
            domain TEXT,
            last_check_date DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    

    
    # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS alerts (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            url TEXT NOT NULL,
            alert_type TEXT NOT NULL,
            message TEXT NOT NULL,
            is_read BOOLEAN DEFAULT 0,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    conn.commit()
    conn.close()

# Initialize database on startup
init_db()

def is_valid_url(url):
    regex = re.compile(
        r'^(?:http|ftp)s?://'
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}\.?)|'
        r'localhost|'
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|'
        r'\[?[A-F0-9]*:[A-F0-9:]+\]?)'
        r'(?::\d+)?'
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return re.match(regex, url) is not None

def get_load_time(url):
    try:
        start_time = time.time()
        response = requests.get(url, timeout=10)
        end_time = time.time()
        return end_time - start_time, response.headers.get('content-length', 0)
    except requests.exceptions.RequestException as e:
        return None, 0

def get_dns_info(url):
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–µ–Ω –∏–∑ URL
        parsed_url = urlparse(url)
        domain = parsed_url.netloc or parsed_url.path.split('/')[0]
        ip_address = socket.gethostbyname(domain)
        return ip_address
    except socket.gaierror:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å DNS –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"

def get_ssl_info(url):
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–µ–Ω –∏–∑ URL
        parsed_url = urlparse(url)
        domain = parsed_url.netloc or parsed_url.path.split('/')[0]
        
        context = ssl.create_default_context()
        conn = context.wrap_socket(socket.socket(socket.AF_INET), server_hostname=domain)
        conn.settimeout(3.0)
        conn.connect((domain, 443))
        ssl_info = conn.getpeercert()
        return ssl_info
    except Exception as e:
        return str(e)

def get_http_headers(url):
    """Get HTTP headers for security analysis"""
    try:
        response = requests.head(url, timeout=10, allow_redirects=True)
        headers = response.headers
        security_info = {}
        
        # Check for security headers
        security_headers = {
            'Strict-Transport-Security': 'HSTS',
            'X-Content-Type-Options': 'X-Content-Type-Options',
            'X-Frame-Options': 'X-Frame-Options',
            'X-XSS-Protection': 'X-XSS-Protection',
            'Content-Security-Policy': 'CSP',
            'Referrer-Policy': 'Referrer-Policy'
        }
        
        for header, name in security_headers.items():
            if header in headers:
                security_info[name] = headers[header]
        
        return security_info
    except Exception as e:
        return {"error": str(e)}

def check_mobile_optimization(url):
    """Check mobile optimization indicators"""
    try:
        response = requests.get(url, timeout=10)
        content = response.text.lower()
        headers = response.headers
        
        mobile_score = 0
        mobile_details = []
        
        # Check for viewport meta tag
        if 'viewport' in content:
            mobile_score += 5
            mobile_details.append("viewport meta tag")
        
        # Check for responsive design indicators
        if 'media=' in content and 'max-width' in content:
            mobile_score += 3
            mobile_details.append("responsive CSS")
        
        # Check for mobile-friendly indicators
        if 'mobile' in content or 'touch' in content:
            mobile_score += 2
            mobile_details.append("mobile indicators")
        
        # Check content length (shorter content loads faster on mobile)
        if len(content) < 50000:  # Less than 50KB
            mobile_score += 2
            mobile_details.append("–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
        
        # Check for image optimization indicators
        if 'lazy' in content or 'loading=' in content:
            mobile_score += 3
            mobile_details.append("lazy loading")
        
        return mobile_score, mobile_details
        
    except Exception as e:
        return 0, ["–æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–±–∏–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"]

def ping_url(url):
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–µ–Ω –∏–∑ URL
    parsed_url = urlparse(url)
    safe_url = parsed_url.netloc or parsed_url.path.split('/')[0]
    
    # –£–±–∏—Ä–∞–µ–º –ø–æ—Ä—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
    if ':' in safe_url:
        safe_url = safe_url.split(':')[0]
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º ping
    ping_result = try_ping_command(safe_url)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ ping –≤–µ—Ä–Ω—É–ª —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (—É—Å–ø–µ—Ö)
    try:
        int(ping_result[0])
        return ping_result
    except (ValueError, TypeError):
        # –ï—Å–ª–∏ ping –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º HTTP-–∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏
        return measure_http_latency(url)

def try_ping_command(host):
    """–ü–æ–ø—ã—Ç–∫–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç—å ping –∫–æ–º–∞–Ω–¥—É"""
    import platform
    system = platform.system().lower()
    
    try:
        if system == "windows":
            # Windows ping - —É–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –∏ —Ç–∞–π–º–∞—É—Ç
            process = subprocess.Popen(['ping', '-n', '2', '-w', '3000', host], 
                                     stdout=subprocess.PIPE, 
                                     stderr=subprocess.PIPE, 
                                     encoding='cp866',
                                     creationflags=subprocess.CREATE_NO_WINDOW)
        else:
            # Linux/Mac ping - —É–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –∏ —Ç–∞–π–º–∞—É—Ç
            process = subprocess.Popen(['ping', '-c', '2', '-W', '3', host], 
                                     stdout=subprocess.PIPE, 
                                     stderr=subprocess.PIPE,
                                     encoding='utf-8')
        
        stdout, stderr = process.communicate(timeout=8)
        
        if process.returncode == 0:
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –û–°
            if system == "windows":
                # Windows: —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤—ã–≤–æ–¥–∞
                patterns = [
                    r'–°—Ä–µ–¥–Ω–µ–µ = (\d+)–º—Å',
                    r'Average = (\d+)ms',
                    r'Average = (\d+)–º—Å',
                    r'–°—Ä–µ–¥–Ω–µ–µ = (\d+)ms',
                    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
                    r'–≤—Ä–µ–º—è=(\d+)–º—Å',
                    r'time=(\d+)ms',
                    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 –∑–Ω–∞—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –∏ –±–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ
                    r'–≤—Ä–µ–º—è=(\d+)–º—Å.*–≤—Ä–µ–º—è=(\d+)–º—Å.*–≤—Ä–µ–º—è=(\d+)–º—Å.*–≤—Ä–µ–º—è=(\d+)–º—Å',
                    r'time=(\d+)ms.*time=(\d+)ms.*time=(\d+)ms.*time=(\d+)ms'
                ]
            else:
                # Linux/Mac: "avg = 45.123 ms"
                patterns = [
                    r'avg = (\d+\.?\d*) ms',
                    r'average = (\d+\.?\d*) ms'
                ]
            
            for pattern in patterns:
                match = re.search(pattern, stdout, re.IGNORECASE)
                if match:
                    if len(match.groups()) == 1:
                        # –û–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
                        avg_ping = match.group(1)
                        try:
                            avg_ping = str(int(float(avg_ping)))
                        except:
                            pass
                        return avg_ping, f"Ping —É—Å–ø–µ—à–µ–Ω: {avg_ping}ms\n{stdout}"
                    elif len(match.groups()) == 4:
                        # –ß–µ—Ç—ã—Ä–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ - –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ
                        times = [int(match.group(i)) for i in range(1, 5)]
                        avg_ping = str(sum(times) // len(times))
                        return avg_ping, f"Ping —É—Å–ø–µ—à–µ–Ω (—Å—Ä–µ–¥–Ω–µ–µ –∏–∑ 4): {avg_ping}ms\n{stdout}"
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ —à–∞–±–ª–æ–Ω–∞–º, –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏
            if system == "windows":
                time_matches = re.findall(r'–≤—Ä–µ–º—è=(\d+)–º—Å', stdout)
                if len(time_matches) >= 2:
                    times = [int(t) for t in time_matches]
                    avg_ping = str(sum(times) // len(times))
                    return avg_ping, f"Ping —É—Å–ø–µ—à–µ–Ω (–∏–∑–≤–ª–µ—á–µ–Ω–æ {len(times)} –∑–Ω–∞—á–µ–Ω–∏–π): {avg_ping}ms\n{stdout}"
            
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–∏–Ω–≥–∞", f"Ping –≤—ã–ø–æ–ª–Ω–µ–Ω, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≤—Ä–µ–º—è:\n{stdout}"
        else:
            return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–∏–Ω–≥–∞", f"Ping –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π (–∫–æ–¥ {process.returncode}):\n{stderr}"
            
    except subprocess.TimeoutExpired:
        if 'process' in locals():
            process.kill()
        return "–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–∏–Ω–≥–∞", "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è (8—Å)"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–∏–Ω–≥–∞: {str(e)}", f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {str(e)}"

def measure_http_latency(url):
    """–ò–∑–º–µ—Ä–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–∫–∏ —á–µ—Ä–µ–∑ HTTP-–∑–∞–ø—Ä–æ—Å—ã"""
    try:
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ URL –∏–º–µ–µ—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        total_time = 0
        successful_requests = 0
        results = []
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º 2 –±—ã—Å—Ç—Ä—ã—Ö HTTP-–∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏
        for i in range(2):
            try:
                start_time = time.time()
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º GET –≤–º–µ—Å—Ç–æ HEAD –¥–ª—è –±–æ–ª—å—à–µ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                response = requests.get(url, timeout=5, allow_redirects=True, stream=True)
                end_time = time.time()
                
                if response.status_code < 400:  # –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç
                    latency = (end_time - start_time) * 1000  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                    total_time += latency
                    successful_requests += 1
                    results.append(f"–ó–∞–ø—Ä–æ—Å {i+1}: {latency:.0f}ms (—Å—Ç–∞—Ç—É—Å: {response.status_code})")
                else:
                    results.append(f"–ó–∞–ø—Ä–æ—Å {i+1}: HTTP {response.status_code}")
                
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
                response.close()
                
            except requests.exceptions.Timeout:
                results.append(f"–ó–∞–ø—Ä–æ—Å {i+1}: –¢–∞–π–º–∞—É—Ç (5—Å)")
            except requests.exceptions.ConnectionError as e:
                results.append(f"–ó–∞–ø—Ä–æ—Å {i+1}: –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è - {str(e)}")
            except requests.exceptions.RequestException as e:
                results.append(f"–ó–∞–ø—Ä–æ—Å {i+1}: –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ - {str(e)}")
            except Exception as e:
                results.append(f"–ó–∞–ø—Ä–æ—Å {i+1}: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ - {str(e)}")
        
        if successful_requests > 0:
            avg_latency = total_time / successful_requests
            result_text = f"HTTP-–∑–∞–¥–µ—Ä–∂–∫–∞ (GET –∑–∞–ø—Ä–æ—Å—ã):\n" + "\n".join(results) + f"\n\n–°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞: {avg_latency:.0f}ms"
            return str(int(avg_latency)), result_text
        else:
            error_details = "\n".join(results)
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–º–µ—Ä–∏—Ç—å HTTP-–∑–∞–¥–µ—Ä–∂–∫—É", f"–í—Å–µ HTTP-–∑–∞–ø—Ä–æ—Å—ã –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å —Å –æ—à–∏–±–∫–æ–π:\n{error_details}"
            
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ—Ä–µ–Ω–∏–∏ HTTP-–∑–∞–¥–µ—Ä–∂–∫–∏: {str(e)}", str(e)

def calculate_seo_score_enhanced(load_time, avg_ping, dns_info, ssl_info, url, http_headers):
    score = 0
    details = []
    
    # Load time scoring (30 points max)
    if load_time < 0.5:
        score += 30
        details.append("üöÄ –ú–æ–ª–Ω–∏–µ–Ω–æ—Å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ (< 0.5—Å)")
    elif load_time < 1:
        score += 25
        details.append("‚ö° –û—Ç–ª–∏—á–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ (< 1—Å)")
    elif load_time < 2:
        score += 20
        details.append("‚úÖ –•–æ—Ä–æ—à–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ (< 2—Å)")
    elif load_time < 3:
        score += 15
        details.append("‚ö†Ô∏è –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ (< 3—Å)")
    elif load_time < 5:
        score += 10
        details.append("üêå –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ (< 5—Å)")
    else:
        details.append("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –º–µ–¥–ª–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (> 5—Å)")
    
    # Ping scoring (20 points max)
    if (avg_ping != "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–∏–Ω–≥–∞" and 
        avg_ping != "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–∏–Ω–≥–∞" and
        avg_ping != "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–º–µ—Ä–∏—Ç—å HTTP-–∑–∞–¥–µ—Ä–∂–∫—É" and
        avg_ping != "–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–∏–Ω–≥–∞" and
        not avg_ping.startswith("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ—Ä–µ–Ω–∏–∏")):
        try:
            ping_num = int(avg_ping)
            if ping_num < 20:
                score += 20
                details.append("üéØ –ò–¥–µ–∞–ª—å–Ω–∞—è —Å–µ—Ç–µ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ (< 20ms)")
            elif ping_num < 50:
                score += 18
                details.append("üèÜ –û—Ç–ª–∏—á–Ω–∞—è —Å–µ—Ç–µ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ (< 50ms)")
            elif ping_num < 100:
                score += 15
                details.append("‚úÖ –•–æ—Ä–æ—à–∞—è —Å–µ—Ç–µ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ (< 100ms)")
            elif ping_num < 200:
                score += 12
                details.append("‚ö†Ô∏è –°—Ä–µ–¥–Ω—è—è —Å–µ—Ç–µ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ (< 200ms)")
            elif ping_num < 500:
                score += 8
                details.append("üêå –í—ã—Å–æ–∫–∞—è —Å–µ—Ç–µ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ (< 500ms)")
            else:
                details.append("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤—ã—Å–æ–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ (> 500ms)")
        except:
            details.append("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–º–µ—Ä–∏—Ç—å —Å–µ—Ç–µ–≤—É—é –∑–∞–¥–µ—Ä–∂–∫—É")
    else:
        details.append("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–º–µ—Ä–∏—Ç—å —Å–µ—Ç–µ–≤—É—é –∑–∞–¥–µ—Ä–∂–∫—É")
    
    # DNS scoring (10 points max)
    if dns_info != "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å DNS –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é":
        score += 10
        details.append("üåê DNS —Ä–µ–∑–æ–ª–≤–∏–Ω–≥ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    else:
        details.append("‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å DNS —Ä–µ–∑–æ–ª–≤–∏–Ω–≥–æ–º")
    
    # SSL scoring (10 points max)
    if "error" not in str(ssl_info).lower() and "exception" not in str(ssl_info).lower():
        score += 10
        details.append("üîí SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –≤–∞–ª–∏–¥–µ–Ω")
    else:
        details.append("‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–º")
    
    # Mobile optimization check (15 points max)
    mobile_score, mobile_details = check_mobile_optimization(url)
    
    # Combine mobile score with load time factor
    if load_time < 2:
        mobile_score += 5
    elif load_time < 3:
        mobile_score += 3
    elif load_time < 5:
        mobile_score += 1
    
    # Cap at 15 points max
    mobile_score = min(mobile_score, 15)
    score += mobile_score
    
    if mobile_score >= 12:
        details.append(f"üì± –û—Ç–ª–∏—á–Ω–∞—è –º–æ–±–∏–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è ({', '.join(mobile_details)})")
    elif mobile_score >= 8:
        details.append(f"üì± –•–æ—Ä–æ—à–∞—è –º–æ–±–∏–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è ({', '.join(mobile_details)})")
    elif mobile_score >= 4:
        details.append(f"üì± –ë–∞–∑–æ–≤–∞—è –º–æ–±–∏–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è ({', '.join(mobile_details)})")
    else:
        details.append("üì± –¢—Ä–µ–±—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏–µ –º–æ–±–∏–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
    
    # URL structure check (5 points max)
    # Real URL structure analysis
    url_clean = True
    url_issues = []
    
    if "?" in url:
        url_clean = False
        url_issues.append("—Å–æ–¥–µ—Ä–∂–∏—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞")
    if "#" in url:
        url_clean = False
        url_issues.append("—Å–æ–¥–µ—Ä–∂–∏—Ç —è–∫–æ—Ä—è")
    if len(url.split("/")) > 4:  # Too many path segments
        url_clean = False
        url_issues.append("—Å–ª–∏—à–∫–æ–º –≥–ª—É–±–æ–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")
    if url.count("//") > 1:  # Multiple protocols
        url_clean = False
        url_issues.append("–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç")
    
    if url_clean:
        score += 5
        details.append("üîó –ß–∏—Å—Ç–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ URL")
    else:
        details.append(f"üîó –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–ª—É—á—à–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É URL: {', '.join(url_issues)}")
    
    # Security headers check (10 points max)
    security_score = 0
    security_details = []
    
    if isinstance(http_headers, dict) and "error" not in http_headers:
        if "HSTS" in http_headers:
            security_score += 3
            security_details.append("HSTS")
        if "X-Content-Type-Options" in http_headers:
            security_score += 2
            security_details.append("X-Content-Type-Options")
        if "X-Frame-Options" in http_headers:
            security_score += 2
            security_details.append("X-Frame-Options")
        if "X-XSS-Protection" in http_headers:
            security_score += 1
            security_details.append("X-XSS-Protection")
        if "CSP" in http_headers:
            security_score += 2
            security_details.append("CSP")
    
    score += security_score
    
    if security_score >= 8:
        details.append("üõ°Ô∏è –û—Ç–ª–∏—á–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å (–≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏)")
    elif security_score >= 5:
        details.append(f"üõ°Ô∏è –•–æ—Ä–æ—à–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å ({', '.join(security_details)})")
    elif security_score >= 2:
        details.append(f"üõ°Ô∏è –ë–∞–∑–æ–≤–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å ({', '.join(security_details)})")
    else:
        details.append("üõ°Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
    
    # Convert to letter grade with detailed feedback
    if score >= 95:
        grade = "S+"
        feedback = "üåü –ò–î–ï–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –°–∞–π—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏!"
    elif score >= 90:
        grade = "S"
        feedback = "üèÜ –û–¢–õ–ò–ß–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –°–∞–π—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å!"
    elif score >= 85:
        grade = "A+"
        feedback = "‚≠ê –í–ï–õ–ò–ö–û–õ–ï–ü–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –°–∞–π—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ!"
    elif score >= 80:
        grade = "A"
        feedback = "‚úÖ –û–¢–õ–ò–ß–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –°–∞–π—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã—Å–æ–∫—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å!"
    elif score >= 75:
        grade = "A-"
        feedback = "üëç –•–û–†–û–®–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –°–∞–π—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ!"
    elif score >= 70:
        grade = "B+"
        feedback = "‚úÖ –•–û–†–û–®–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –ï—Å—Ç—å –Ω–µ–±–æ–ª—å—à–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è!"
    elif score >= 65:
        grade = "B"
        feedback = "‚ö†Ô∏è –°–†–ï–î–ù–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è!"
    elif score >= 60:
        grade = "B-"
        feedback = "‚ö†Ô∏è –°–†–ï–î–ù–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –¢—Ä–µ–±—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏!"
    elif score >= 55:
        grade = "C+"
        feedback = "üêå –ù–ò–ó–ö–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –ù–µ–æ–±—Ö–æ–¥–∏–º–∞ —Å–µ—Ä—å–µ–∑–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è!"
    elif score >= 50:
        grade = "C"
        feedback = "üêå –ù–ò–ó–ö–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è!"
    elif score >= 40:
        grade = "D"
        feedback = "‚ùå –ü–õ–û–•–û–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –°–∞–π—Ç —Ç—Ä–µ–±—É–µ—Ç –ø–æ–ª–Ω–æ–π –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏!"
    else:
        grade = "F"
        feedback = "üíÄ –ö–ê–¢–ê–°–¢–†–û–§–ò–ß–ï–°–ö–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –°–∞–π—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!"
    
    return grade, feedback, details, score

def save_analysis(url, load_time, dns_info, ssl_info, avg_ping, ping_result, page_size, seo_score):
    conn = sqlite3.connect('sonic_boom.db')
    cursor = conn.cursor()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–µ–Ω –∏–∑ URL
    parsed_url = urlparse(url)
    domain = parsed_url.netloc or parsed_url.path.split('/')[0]
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º SEO —Ä–µ–π—Ç–∏–Ω–≥ –≤ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    seo_score_numeric = convert_seo_to_numeric(seo_score)
    
    cursor.execute('''
        INSERT INTO analysis_history 
        (url, load_time, dns_info, ssl_info, avg_ping, ping_result, page_size, seo_score, seo_score_numeric, domain, last_check_date)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
    ''', (url, load_time, dns_info, str(ssl_info), avg_ping, ping_result, page_size, seo_score, seo_score_numeric, domain))
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —É—Ö—É–¥—à–µ–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
    check_for_degradation(url, seo_score_numeric, load_time)
    
    conn.commit()
    conn.close()

def convert_seo_to_numeric(seo_score):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –±—É–∫–≤–µ–Ω–Ω—ã–π SEO —Ä–µ–π—Ç–∏–Ω–≥ –≤ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"""
    score_map = {
        'S+': 100, 'S': 95, 'A+': 90, 'A': 85, 'A-': 80,
        'B+': 75, 'B': 70, 'B-': 65, 'C+': 60, 'C': 55,
        'C-': 50, 'D+': 45, 'D': 40, 'D-': 35, 'F': 30
    }
    return score_map.get(seo_score, 0)

def check_for_degradation(url, current_score, current_load_time):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É—Ö—É–¥—à–µ–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –∏ —Å–æ–∑–¥–∞–µ—Ç –∞–ª–µ—Ä—Ç—ã"""
    conn = sqlite3.connect('sonic_boom.db')
    cursor = conn.cursor()
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∞–Ω–∞–ª–∏–∑
    cursor.execute('''
        SELECT seo_score_numeric, load_time FROM analysis_history 
        WHERE url = ? AND id != (SELECT MAX(id) FROM analysis_history WHERE url = ?)
        ORDER BY timestamp DESC LIMIT 1
    ''', (url, url))
    
    result = cursor.fetchone()
    if result:
        prev_score, prev_load_time = result
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Ö—É–¥—à–µ–Ω–∏–µ SEO —Ä–µ–π—Ç–∏–Ω–≥–∞
        if current_score < prev_score - 10:  # –£—Ö—É–¥—à–µ–Ω–∏–µ –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 10 –±–∞–ª–ª–æ–≤
            cursor.execute('''
                INSERT INTO alerts (url, alert_type, message)
                VALUES (?, 'seo_degradation', ?)
            ''', (url, f'SEO —Ä–µ–π—Ç–∏–Ω–≥ —É—Ö—É–¥—à–∏–ª—Å—è —Å {prev_score} –¥–æ {current_score}'))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Ö—É–¥—à–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–≥—Ä—É–∑–∫–∏
        if current_load_time and prev_load_time and current_load_time > prev_load_time * 1.5:
            cursor.execute('''
                INSERT INTO alerts (url, alert_type, message)
                VALUES (?, 'performance_degradation', ?)
            ''', (url, f'–í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ —É–≤–µ–ª–∏—á–∏–ª–æ—Å—å —Å {prev_load_time:.3f}s –¥–æ {current_load_time:.3f}s'))
    
    conn.commit()
    conn.close()

def get_analysis_history(limit=10):
    conn = sqlite3.connect('sonic_boom.db')
    cursor = conn.cursor()
    cursor.execute('''
        SELECT * FROM analysis_history 
        ORDER BY timestamp DESC 
        LIMIT ?
    ''', (limit,))
    results = cursor.fetchall()
    conn.close()
    
    # Convert to list of dictionaries with all new fields
    columns = ['id', 'url', 'load_time', 'dns_info', 'ssl_info', 'avg_ping', 'ping_result', 'page_size', 'seo_score', 'seo_score_numeric', 'timestamp', 'is_favorite', 'tags', 'notes', 'domain', 'last_check_date']
    
    # Handle cases where old records might not have all columns
    history = []
    for row in results:
        record = {}
        for i, column in enumerate(columns):
            if i < len(row):
                record[column] = row[i]
            else:
                # Default values for missing columns
                if column == 'is_favorite':
                    record[column] = False
                elif column in ['tags', 'notes', 'domain']:
                    record[column] = None
                elif column == 'seo_score_numeric':
                    record[column] = convert_seo_to_numeric(record.get('seo_score', 'F'))
                else:
                    record[column] = None
        history.append(record)
    
    return history

def clear_analysis_history():
    conn = sqlite3.connect('sonic_boom.db')
    cursor = conn.cursor()
    cursor.execute('DELETE FROM analysis_history')
    deleted_count = cursor.rowcount
    conn.commit()
    conn.close()
    return deleted_count

def delete_analysis_by_id(analysis_id):
    conn = sqlite3.connect('sonic_boom.db')
    cursor = conn.cursor()
    cursor.execute('DELETE FROM analysis_history WHERE id = ?', (analysis_id,))
    deleted_count = cursor.rowcount
    conn.commit()
    conn.close()
    return deleted_count

@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST':
        url = request.form['url']
        if is_valid_url(url):
            # Get analysis data
            load_time, page_size = get_load_time(url)
            if load_time is None:
                return render_template('index.html', error="–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–∞–π—Ç")
            
            dns_info = get_dns_info(url)
            ssl_info = get_ssl_info(url)
            avg_ping, ping_result = ping_url(url)
            
            # Get HTTP headers for security analysis
            http_headers = get_http_headers(url)
            
            # Calculate SEO score with enhanced analysis
            seo_grade, seo_feedback, seo_details, seo_score_value = calculate_seo_score_enhanced(load_time, avg_ping, dns_info, ssl_info, url, http_headers)
            
            # Save to database
            save_analysis(url, load_time, dns_info, ssl_info, avg_ping, ping_result, page_size, seo_grade)
            
            return render_template('result.html', 
                                url=url, 
                                load_time=load_time, 
                                dns_info=dns_info, 
                                ssl_info=ssl_info, 
                                avg_ping=avg_ping, 
                                ping_result=ping_result,
                                page_size=page_size,
                                seo_grade=seo_grade,
                                seo_feedback=seo_feedback,
                                seo_details=seo_details,
                                seo_score_value=seo_score_value,
                                http_headers=http_headers)
        else:
            error = "–ù–µ–≤–µ—Ä–Ω—ã–π URL"
            return render_template('index.html', error=error)
    return render_template('index.html')

# API Endpoints

@app.route('/api/history', methods=['GET'])
def api_history():
    limit = request.args.get('limit', 10, type=int)
    history = get_analysis_history(limit)
    return jsonify(history)

@app.route('/api/stats', methods=['GET'])
def api_stats():
    conn = sqlite3.connect('sonic_boom.db')
    cursor = conn.cursor()
    
    # Get total analyses
    cursor.execute('SELECT COUNT(*) FROM analysis_history')
    total_analyses = cursor.fetchone()[0]
    
    # Get average load time
    cursor.execute('SELECT AVG(load_time) FROM analysis_history WHERE load_time IS NOT NULL')
    avg_load_time = cursor.fetchone()[0] or 0
    
    # Get most analyzed URLs
    cursor.execute('''
        SELECT url, COUNT(*) as count 
        FROM analysis_history 
        GROUP BY url 
        ORDER BY count DESC 
        LIMIT 5
    ''')
    top_urls = [{'url': row[0], 'count': row[1]} for row in cursor.fetchall()]
    
    conn.close()
    
    return jsonify({
        'total_analyses': total_analyses,
        'average_load_time': round(avg_load_time, 3),
        'top_urls': top_urls
    })

@app.route('/api/clear-history', methods=['DELETE'])
def api_clear_history():
    try:
        deleted_count = clear_analysis_history()
        return jsonify({
            'success': True,
            'message': f'–£–¥–∞–ª–µ–Ω–æ {deleted_count} –∑–∞–ø–∏—Å–µ–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏',
            'deleted_count': deleted_count
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/delete-analysis/<int:analysis_id>', methods=['DELETE'])
def api_delete_analysis(analysis_id):
    try:
        deleted_count = delete_analysis_by_id(analysis_id)
        if deleted_count > 0:
            return jsonify({
                'success': True,
                'message': '–ó–∞–ø–∏—Å—å —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞',
                'deleted_count': deleted_count
            })
        else:
            return jsonify({
                'success': False,
                'error': '–ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'
            }), 404
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500



# –ù–æ–≤—ã–µ API endpoints –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏

@app.route('/api/history/filter', methods=['GET'])
def api_filter_history():
    """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –∞–Ω–∞–ª–∏–∑–æ–≤"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        date_from = request.args.get('date_from')
        date_to = request.args.get('date_to')
        seo_score = request.args.get('seo_score')
        load_time_min = request.args.get('load_time_min', type=float)
        load_time_max = request.args.get('load_time_max', type=float)
        domain = request.args.get('domain')
        favorites_only = request.args.get('favorites_only', type=bool)
        tags = request.args.get('tags')
        
        conn = sqlite3.connect('sonic_boom.db')
        cursor = conn.cursor()
        
        # –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        query = '''
            SELECT * FROM analysis_history WHERE 1=1
        '''
        params = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        if date_from:
            query += ' AND DATE(timestamp) >= ?'
            params.append(date_from)
        
        if date_to:
            query += ' AND DATE(timestamp) <= ?'
            params.append(date_to)
        
        if seo_score:
            query += ' AND seo_score = ?'
            params.append(seo_score)
        
        if load_time_min is not None:
            query += ' AND load_time >= ?'
            params.append(load_time_min)
        
        if load_time_max is not None:
            query += ' AND load_time <= ?'
            params.append(load_time_max)
        
        if domain:
            query += ' AND domain LIKE ?'
            params.append(f'%{domain}%')
        
        if favorites_only:
            query += ' AND is_favorite = 1'
        
        if tags:
            query += ' AND tags LIKE ?'
            params.append(f'%{tags}%')
        
        query += ' ORDER BY timestamp DESC'
        
        cursor.execute(query, params)
        results = cursor.fetchall()
        conn.close()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
        columns = ['id', 'url', 'load_time', 'dns_info', 'ssl_info', 'avg_ping', 'ping_result', 'page_size', 'seo_score', 'seo_score_numeric', 'timestamp', 'is_favorite', 'tags', 'notes', 'domain', 'last_check_date']
        history = [dict(zip(columns, row)) for row in results]
        
        return jsonify(history)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/analytics', methods=['GET'])
def api_analytics():
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞"""
    try:
        conn = sqlite3.connect('sonic_boom.db')
        cursor = conn.cursor()
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ SEO —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
        cursor.execute('''
            SELECT seo_score, COUNT(*) as count 
            FROM analysis_history 
            GROUP BY seo_score 
            ORDER BY seo_score_numeric DESC
        ''')
        seo_distribution = [{'score': row[0], 'count': row[1]} for row in cursor.fetchall()]
        
        # –¢–æ–ø –¥–æ–º–µ–Ω–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∞–Ω–∞–ª–∏–∑–æ–≤
        cursor.execute('''
            SELECT domain, COUNT(*) as count, AVG(seo_score_numeric) as avg_score
            FROM analysis_history 
            WHERE domain IS NOT NULL
            GROUP BY domain 
            ORDER BY count DESC 
            LIMIT 10
        ''')
        top_domains = [{'domain': row[0], 'count': row[1], 'avg_score': round(row[2], 1)} for row in cursor.fetchall()]
        
        # –¢—Ä–µ–Ω–¥ SEO —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        cursor.execute('''
            SELECT DATE(timestamp) as date, AVG(seo_score_numeric) as avg_score
            FROM analysis_history 
            WHERE timestamp >= DATE('now', '-30 days')
            GROUP BY DATE(timestamp)
            ORDER BY date
        ''')
        seo_trend = [{'date': row[0], 'avg_score': round(row[1], 1)} for row in cursor.fetchall()]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–≥—Ä—É–∑–∫–∏
        cursor.execute('''
            SELECT 
                COUNT(CASE WHEN load_time < 1 THEN 1 END) as fast,
                COUNT(CASE WHEN load_time >= 1 AND load_time < 3 THEN 1 END) as medium,
                COUNT(CASE WHEN load_time >= 3 THEN 1 END) as slow
            FROM analysis_history 
            WHERE load_time IS NOT NULL
        ''')
        load_time_stats = cursor.fetchone()
        
        conn.close()
        
        return jsonify({
            'seo_distribution': seo_distribution,
            'top_domains': top_domains,
            'seo_trend': seo_trend,
            'load_time_stats': {
                'fast': load_time_stats[0],
                'medium': load_time_stats[1],
                'slow': load_time_stats[2]
            }
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/favorites', methods=['POST'])
def api_toggle_favorite():
    """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –∏–∑–±—Ä–∞–Ω–Ω–æ–≥–æ"""
    try:
        data = request.get_json()
        analysis_id = data.get('analysis_id')
        is_favorite = data.get('is_favorite', True)
        
        conn = sqlite3.connect('sonic_boom.db')
        cursor = conn.cursor()
        cursor.execute('UPDATE analysis_history SET is_favorite = ? WHERE id = ?', (is_favorite, analysis_id))
        conn.commit()
        conn.close()
        
        return jsonify({'success': True, 'is_favorite': is_favorite})
    except Exception as e:
        return jsonify({'error': str(e)}), 500



@app.route('/api/alerts', methods=['GET', 'POST'])
def api_alerts():
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–ª–µ—Ä—Ç–∞–º–∏"""
    try:
        conn = sqlite3.connect('sonic_boom.db')
        cursor = conn.cursor()
        
        if request.method == 'GET':
            # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∞–ª–µ—Ä—Ç—ã
            cursor.execute('SELECT * FROM alerts ORDER BY created_at DESC LIMIT 50')
            alerts = cursor.fetchall()
            columns = ['id', 'url', 'alert_type', 'message', 'is_read', 'created_at']
            return jsonify([dict(zip(columns, row)) for row in alerts])
        
        elif request.method == 'POST':
            # –û—Ç–º–µ—Ç–∏—Ç—å –∞–ª–µ—Ä—Ç –∫–∞–∫ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–π
            data = request.get_json()
            alert_id = data.get('alert_id')
            cursor.execute('UPDATE alerts SET is_read = 1 WHERE id = ?', (alert_id,))
            conn.commit()
            
            return jsonify({'success': True})
        
        conn.close()
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/export/<format>')
def api_export(format):
    """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
    try:
        conn = sqlite3.connect('sonic_boom.db')
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM analysis_history ORDER BY timestamp DESC')
        results = cursor.fetchall()
        conn.close()
        
        columns = ['id', 'url', 'load_time', 'dns_info', 'ssl_info', 'avg_ping', 'ping_result', 'page_size', 'seo_score', 'seo_score_numeric', 'timestamp', 'is_favorite', 'tags', 'notes', 'domain', 'last_check_date']
        
        if format == 'csv':
            import csv
            import io
            
            output = io.StringIO()
            writer = csv.writer(output)
            writer.writerow(columns)
            writer.writerows(results)
            
            return Response(
                output.getvalue(),
                mimetype='text/csv',
                headers={'Content-Disposition': 'attachment; filename=analysis_history.csv'}
            )
        
        elif format == 'json':
            history = [dict(zip(columns, row)) for row in results]
            return jsonify(history)
        
        else:
            return jsonify({'error': 'Unsupported format'}), 400
            
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# History page
@app.route('/history')
def history():
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é"""
    return render_template('history.html')



@app.errorhandler(404)
def page_not_found(e):
    return render_template('404.html'), 404

@app.errorhandler(500)
def internal_server_error(e):
    return render_template('500.html'), 500

if __name__ == '__main__':
    app.run(debug=True)